<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Besim Kabashi">
  <title>Besim Kabashi – Resources</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="kabashi.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<script src="jquery-3.3.1.min.js" type="text/javascript"></script>
<script type="text/javascript">
  $(function(){
    var url = window.location.href;
    if (url == "https://besim-kabashi.net/" || url == "https://www.besim-kabashi.net") {
      url = "https://www.besim-kabashi.net/index.html"
    }
    url = url.replace(/#.+$/, "");
    $("nav a").each(function() {
      if (url == (this.href)) {
        $(this).addClass("current");
      }
    });
    $("#topnav_id").attr("class", "topnav_js");
    $("#menu_link_id").attr("class", "menu_link_js");
  });
  /* Add/remove the "responsive" class when clicking on the menu icon */
  function toggle_nav() {
    var navi = document.getElementById("topnav_id");
    if (navi.className === "topnav_js") {
      navi.className += " responsive";
    } else {
      navi.className = "topnav_js";
    }
  } 
</script>

<header class="navigation">
  <h1><a>Besim Kabashi</a></h1>
  <h4><a>[ <i> Human Language Processing and Technology · Knowledge Resources · Intelligence </i> ]</a></h4>
  
<nav class="topnav" id="topnav_id">
  <a href="index.html"> Home </a> 
  <a href="research.html"> Research </a> 
  <a href="publications.html"> Publications </a> 
  <a href="projects.html"> Projects </a>
  <a href="resources.html"> Resources </a>
  <a href="events.html"> Events </a>
  <a href="teaching.html"> Teaching </a>
  <a href="cv.html"> CV </a>
</nav>
</header>
<main>
<!-- <header> -->
<h1 class="title">Resources</h1>
<!--  -->
<!-- <h2 class="author">Besim Kabashi</h2> -->
<!--  -->
<!--  -->
<!-- </header> -->
<ul>
<li><a href="#data-sets">Data Sets</a></li>
<li><a href="#corpora">Corpora</a></li>
</ul>
<h2 id="data-sets">Data Sets</h2>
<ul>
<li><h3 id="empirist-corpus-2.0">EmpiriST Corpus 2.0</h3>
The EmpiriST Corpus 2.0 is a manually annotated corpus consisting of German web pages and German computer-mediated communication (CMC), i.e. written discourse. Examples for CMC genres are monologic and dialogic tweets, social and professional chats, threads from Wikipedia talk pages, WhatsApp interactions and blog comments.<br />
<br />
The dataset was originally created by <a href="https://www.aclweb.org/anthology/W16-2606/">Beißwenger et al. (2016)</a> for the <a href="https://sites.google.com/site/empirist2015/">EmpiriST 2015</a> shared task and featured manual tokenization and part-of-speech tagging. Subsequently, <a href="https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/konvens18_03.pdf">Rehbein et al. (2018)</a> incorporated the dataset into their <a href="https://www.cl.uni-heidelberg.de/~rehbein/tweeDe.mhtml">harmonised testsuite for POS tagging of German social media data</a>, manually added sentence boundaries and automatically mapped the part-of-speech tags to <a href="https://universaldependencies.org/u/pos/all.html">UD pos tags</a>. In our own annotation efforts (Proisl et al., in preparation), we manually normalized and lemmatized the data and converted the corpus into a “vertical” format suitable for importing into the Open Corpus Workbench, CQPweb, SketchEngine, or similar corpus tools.<br />
<br />
Normalization and lemmatization added in collaboration with <a href="https://thomas-proisl.de">Thomas Proisl</a>, Natalie Dykes, <a href="https://philipp-heinrich.eu/">Philipp Heinrich</a>, and <a href="http://stefan-evert.de/">Stefan Evert</a>.<br />
<br />
–&gt; See the data set (and the description) on <a href="https://github.com/fau-klue/empirist-corpus">GitHub</a>.</li>
</ul>
<h2 id="corpora">Corpora</h2>
<ul>
<li><h3 id="gerede-a-corpus-of-german-reddit-exchanges">GeRedE: A Corpus of German Reddit Exchanges</h3>
<p>GeRedE is a 270 million token German CMC corpus containing approximately 380,000 submissions and 6,800,000 comments posted on Reddit between 2010 and 2018. Created in collaboration with Andreas Blombach, Natalie Dykes, <a href="https://philipp-heinrich.eu/">Philipp Heinrich</a> and <a href="https://thomas-proisl.de/">Thomas Proisl</a>.<br />
<br />
–&gt; See the data set (and the description) on <a href="https://github.com/fau-klue/german-reddit-korpus">GitHub</a>.</p></li>
<li><h3 id="albanian-corpus-alco">Albanian Corpus (AlCo)</h3>
<p>The Albanian Corpus (AlCo) contains a hundred million word tokens (text words), the first Albanian corpus of this size. The corpus covers different domains of language and contains different text types – it is a reference corpus. At this moment the work is still in progress, some texts still need to be replaced or recategorized. The corpus is annotated with a morpho-syntactic tagset of 77 tags, since 2015. We use CQPweb, a web-based corpus analysis system, to explore the corpus data.</p></li>
<li><h3 id="alcopress-2017-2019">AlCoPress (2017-2019)</h3>
<p>The Albanian Corpus of Press Texts (AlCo) contains around 32 million word tokens (text words). The corpus is annotated like AlCo. We use CQPweb, a web-based corpus analysis system, to explore the corpus data.</p></li>
<li><h3 id="buzuku-1555-corpus">Buzuku (1555) Corpus</h3>
<p>The Buzuku Corpus contains the text of “Missale” (1555) from Gjon Buzuku. The corpus is not annotated.</p></li>
</ul>
<!-- ## News ## -->
<footer>
  Last modified: 2021-06-14.
</footer>
</body>
</html>
